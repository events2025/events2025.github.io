---
title: ðŸŸ£ Notable Papers and Methods
nav_order: 7
layout: home
---

<h1 style="color: purple;">Notable Papers and Methods</h1>
<br>

<div style="max-width: 100%;">
  <!-- START -->
<div style="display: flex; justify-content: space-between; align-items: stretch; margin-bottom: 20px;">
    <div style="display: flex; align-items: stretch;">
      <img src="/assets/image/in_data_we_trust_a_comparison_of_ucdp_ged_and_acled_conflict_events_datasets.jpg" alt="Logo" style="width: 100px; height: 100px; margin-right: 20px;">
      <div style="flex-grow: 1; display: flex; flex-direction: column; justify-content: space-between;">
        <p style="margin: 0; color: purple; font-size: 1.3em; font-weight: bold;">In data we trust? A comparison of UCDP GED and ACLED conflict events datasets</p>
        <p style="margin: 0;">This paper examines the strengths and weaknesses of two prominent conflict event datasets, the UCDP Georeferenced Event Dataset (UCDP GED) and the Armed Conflict Location and Event Dataset (ACLED), which have facilitated microlevel analyses of civil war dynamics. It discusses differences in scope, definitions, and data collection processes, highlighting issues like UCDP GEDâ€™s focus on fatalities and ACLEDâ€™s inclusion of non-fatal and non-violent events. The paper uses georeferenced, disaggregated event data, primarily from Africa, detailing specific cases to evaluate coding quality and methodological challenges in both datasets.</p>
        <p style="margin: 0;"><a href="https://journals.sagepub.com/doi/10.1177/0010836711434463"><i class="fa-regular fa-file-pdf"></i>https://journals.sagepub.com/doi/10.1177/0010836711434463</a> </p>
      </div>
    </div>
    <!-- <div style="color: lightgray; align-self: flex-start; margin-left: 10px; white-space: nowrap; font-size: 200%;">2022</div>  -->
  </div>

<div style="display: flex; justify-content: space-between; align-items: stretch; margin-bottom: 20px;">
    <div style="display: flex; align-items: stretch;">
      <img src="/assets/image/neural_jump-diffusion_temporal_point_processes.jpg" alt="Logo" style="width: 100px; height: 100px; margin-right: 20px;">
      <div style="flex-grow: 1; display: flex; flex-direction: column; justify-content: space-between;">
        <p style="margin: 0; color: purple; font-size: 1.3em; font-weight: bold;">Neural Jump-Diffusion Temporal Point Processes</p>
        <p style="margin: 0;">The paper introduces a framework that models temporal point processes (TPPs) using neural jump-diffusion stochastic differential equations (SDEs).  Motivation: Traditional TPP models often rely on predefined functional forms, which can limit their flexibility in capturing complex event dynamics. To address this limitation, the authors propose reformulating the intensity processes of TPPs as solutions to neural jump-diffusion SDEs. This approach aims to improve the model's capacity to represent intricate temporal patterns without being constrained by specific functional assumptions. Method Description: The proposed framework, termed Neural Jump-Diffusion Temporal Point Process (NJDTPP), models the intensity function of a TPP using a neural jump-diffusion SDE (NJDSDE). In this setup, the SDE's drift, diffusion, and jump coefficients are parameterized by neural networks, allowing the model to learn complex dependencies from data. This design offers theoretical guarantees regarding the existence and uniqueness of solutions to the NJDSDE. Datasets Used: The authors evaluate NJDTPP on both synthetic and real-world datasets: Synthetic Datasets: Poisson Process, Hawkes Process, Self-Correcting Process Real-World Datasets: Retweet Data, Earthquake Records, Taxi Rides, Taobao User Behavior, StackOverflow Activity, MIMIC-II Clinical Database</p>
        <p style="margin: 0;"><a href="https://openreview.net/forum?id=d1P6GtRzuV"><i class="fa-regular fa-file-pdf"></i>https://openreview.net/forum?id=d1P6GtRzuV</a> </p>
      </div>
    </div>
    <!-- <div style="color: lightgray; align-self: flex-start; margin-left: 10px; white-space: nowrap; font-size: 200%;">2022</div>  -->
  </div>
<!-- STOP -->
</div>
